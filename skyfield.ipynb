{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {font-family:Times; font-size:20pt}\n",
    "    h2 {font-family:Times; font-size:18pt}\n",
    "    h3 {font-family:Times; font-size:16pt}\n",
    "    p {font-family:Times; font-size:12pt}\n",
    "    </style>\n",
    "    \n",
    "> # Earth Satellites\n",
    ">\n",
    "> Skyfield is able to predict the positions of Earth satellites by loading satellite orbital elements from Two-Line Element (TLE) files — published by organizations like CelesTrak — and running them through the SGP4 satellite propagation routine. \n",
    "\n",
    "## TLE file format:\n",
    ">AAAAAAAAAAAAAAAAAAAAAAAA\n",
    "\n",
    ">1 NNNNNU NNNNNAAA NNNNN.NNNNNNNN +.NNNNNNNN +NNNNN-N +NNNNN-N N NNNNN\n",
    "\n",
    ">2 NNNNN NNN.NNNN NNN.NNNN NNNNNNN NNN.NNNN NNN.NNNN NN.NNNNNNNNNNNNNN\n",
    "\n",
    "- Line 0:  corresponds to the Satelletie catalog number (NORAD SATCAT) = (the name of the satellite)\n",
    "- Line 1:\n",
    "\n",
    "Reference : https://celestrak.com/NORAD/documentation/tle-fmt.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import os\n",
    "\n",
    "from skyfield.api import load, wgs84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {font-family:Times; font-size:20pt}\n",
    "    h2 {font-family:Times; font-size:18pt}\n",
    "    h3 {font-family:Times; font-size:16pt}\n",
    "    p {font-family:Times; font-size:12pt}\n",
    "    </style>\n",
    "    \n",
    "> ## Loading a TLE file\n",
    ">\n",
    "> Skyfield loader objects offer a tle_file() method that can download and cache a file full of satellite elements from a site like Celestrak. A popular observing target for satellite observers is the International Space Station, which is listed in Celestrak’s stations.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations_url = 'https://www.celestrak.com/NORAD/elements/geo.txt' # Retrieve geo satellite from celestrak\n",
    "stations_url = 'https://celestrak.com/NORAD/elements/weather.txt' # Retrieve weather satellites\n",
    "\n",
    "\n",
    "satellites = load.tle_file(stations_url, reload=False)\n",
    "\n",
    "by_name = {sat.name: sat for sat in satellites}\n",
    "satellite = by_name['METOP-B']\n",
    "\n",
    "print(satellite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {font-family:Times; font-size:20pt}\n",
    "    h2 {font-family:Times; font-size:18pt}\n",
    "    h3 {font-family:Times; font-size:16pt}\n",
    "    p {font-family:Times; font-size:12pt}\n",
    "    </style>\n",
    "    \n",
    "> ## Loading a TLE set from strings\n",
    "> If your program already has the two lines of TLE data for a satellite and doesn’t need Skyfield to download and parse a Celestrak file, you can instantiate an EarthSatellite directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import EarthSatellite\n",
    "\n",
    "ts = load.timescale()\n",
    "#line1 = '1 38771U 12049A   21328.15653177  .00000019  00000+0  28851-4 0  9990'\n",
    "#line2 = '2 38771  98.6954  26.0543 0000110 196.3188 189.2859 14.21494351476561'\n",
    "#line1 = '1 38771U 12049A   21345.19892716  .00000005  00000+0  22412-4 0  9999'\n",
    "#line2 = '2 38771  98.6932  42.8377 0000999 161.9725 266.8848 14.21496788478982'\n",
    "\n",
    "#satellite = EarthSatellite(line1, line2, 'METOP-A', ts)\n",
    "\n",
    "#print(ts)\n",
    "#print(satellite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {font-family:Times; font-size:20pt}\n",
    "    h2 {font-family:Times; font-size:18pt}\n",
    "    h3 {font-family:Times; font-size:16pt}\n",
    "    p {font-family:Times; font-size:12pt}\n",
    "    </style>\n",
    ">\n",
    "> ## Satellite altitude, azimuth, and distance\n",
    ">\n",
    "> You might be most interested in whether the satellite is above or below the horizon from your own position as an observer, and in which direction to look for it. If you build an object to represent your latitude and longitude , you can use vector subtraction to ask “where will the satellite be relative to my location?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lavrion = wgs84.latlon(37.72, 24.048)\n",
    "Ljubljana = wgs84.latlon(46.056, 14.506)\n",
    "difference = satellite - Ljubljana\n",
    "\n",
    "dates = pd.date_range(\"2020-01-01\",\"2021-01-1\",freq='60S')\n",
    "alt = np.zeros(np.size(dates)) * np.nan\n",
    "az = np.zeros(np.size(dates)) * np.nan\n",
    "distances = np.zeros(np.size(dates)) * np.nan\n",
    "\n",
    "print(dates.shape)\n",
    "count = 0\n",
    "\n",
    "city_name = \"lavrion\" ## Edit here to save in another file ljubljana ou lavrion\n",
    "pkl_name= f\"./coordinates_{city_name}.pkl\" \n",
    "pkl_pdf_name= f\"./stat_{city_name}.pkl\" \n",
    "pkl_available = True\n",
    "\n",
    "try:\n",
    "    coord_df = pd.DataFrame(pd.read_pickle(pkl_name))\n",
    "except:\n",
    "    pkl_available=False\n",
    "\n",
    "print(pkl_available)\n",
    "if (pkl_available==False):\n",
    "    for ii,date in enumerate(dates):\n",
    "        count+=1\n",
    "        if (count%100000==0) :\n",
    "            print(count)\n",
    "        t = ts.utc(date.year, date.month, date.day, date.hour, date.minute, date.second)\n",
    "\n",
    "        topocentric = difference.at(t)\n",
    "\n",
    "        alt_, az_, distance = topocentric.altaz()\n",
    "        \n",
    "        distances[ii] = distance.km\n",
    "        alt[ii] = alt_.degrees\n",
    "        az[ii] = az_.degrees\n",
    "\n",
    "    coord_df = pd.DataFrame(index = dates)\n",
    "\n",
    "    # ind = np.nonzero(alt<5)\n",
    "\n",
    "    # alt[ind] = np.nan\n",
    "    # az[ind] = np.nan \n",
    "\n",
    "    coord_df['EL'] = alt \n",
    "    coord_df['AZ'] = az \n",
    "    coord_df['DISTANCES'] = distances\n",
    "\n",
    "    coord_df.to_pickle(pkl_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting\")\n",
    "Plot = True\n",
    "if Plot:\n",
    "    fig, ax = plt.subplots(dpi=200)\n",
    "    ax = coord_df.plot(ax=ax, y='EL', linestyle='solid', marker='')\n",
    "\n",
    "    ax.grid(b=True, which='major', axis='both')\n",
    "    ax.axhline(y=5, color='r', linestyle='-')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {font-family:Times; font-size:20pt}\n",
    "    h2 {font-family:Times; font-size:18pt}\n",
    "    h3 {font-family:Times; font-size:16pt}\n",
    "    p {font-family:Times; font-size:12pt}\n",
    "    </style>\n",
    ">\n",
    "> ## Probability density function\n",
    ">\n",
    "> In this section the probability density function for elevation angle will be calculated $P(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = 5\n",
    "bins = np.arange(5,91,stp) # Regroup in block of 5°, threshold \n",
    "stat = pd.DataFrame(index=bins)\n",
    "\n",
    "for bin in bins:\n",
    "    ind  = np.logical_and( bin <= coord_df['EL'] , coord_df['EL'] < bin+stp) # For all elevation that are in the range bin, bin+stp\n",
    "\n",
    "    el = coord_df.loc[ind,'EL'] # Select all elevation that are in the current bin, bin+stp range\n",
    "\n",
    "    stat.loc[bin,'PDF'] = np.size(el)/np.size(ind) * 100 # Probability of presensce in the current bin: PDF = (#number of element in the current bin)/(#number total number of element)\n",
    "\n",
    "# Save pdf to pickle\n",
    "stat.to_pickle(pkl_pdf_name)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200)\n",
    "ax = stat.plot(ax=ax, y='PDF', kind='bar')\n",
    "ax.grid(b=True, which='major', axis='y')\n",
    "\n",
    "ax.set_xlabel(r'Elevation [$^\\circ$]')\n",
    "ax.set_ylabel(r'Probability [%]')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load picke pdf, if pdf was already computed\n",
    "stat = pd.read_pickle(pkl_pdf_name)\n",
    "stat['PDF'] = stat['PDF']/stat['PDF'].sum() * 100\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200)\n",
    "ax = stat.plot(ax=ax, y='PDF', kind='bar')\n",
    "ax.grid(b=True, which='major', axis='y')\n",
    "\n",
    "ax.set_xlabel(r'Elevation [$^\\circ$]')\n",
    "ax.set_ylabel(r'Probability [%]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute average of attenuation\n",
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folders_name = [\"Lavrion-37.5GHz-5-50\", \"Lavrion-37.5GHz-55-89.9\", \"Lavrion-75GHz-5-50\", \"Lavrion-75-GHz-55-89.9\", \"Ljubljana-37.5GHz-5-50\", \"Ljubljana-37.5GHZ-55-89.9\", \"Ljubljana-75GHz-5-50\", \"Ljubljana-75GHz-55-89.9\"]\n",
    "\n",
    "attenuations_file = {'total': \"attenuation_total.csv\", \"cloud\": \"attenuation_cloud.csv\", \"oxygen\":\"attenuation_oxygen.csv\", \"rain\":\"attenuation_rain.csv\", \"scintillation\":\"attenuation_scintillation.csv\"}\n",
    "att_columns = {'total':'att_comb_dB', 'cloud':'att_cld_dB', 'oxygen':'', 'rain':'att_rain_dB', 'scintillation':'att_scin_dB'}\n",
    "\n",
    "selected_attenuation = 'total' ## Change here to select another atenuation\n",
    "\n",
    "file_name = attenuations_file[selected_attenuation]\n",
    "att_col = att_columns[selected_attenuation]\n",
    "header = 6\n",
    "\n",
    "df_lavrion_375_1 = pd.read_csv(f\"data/{folders_name[0]}/output/ascii/{file_name}\",header=header)\n",
    "df_lavrion_375_2 = pd.read_csv(f\"data/{folders_name[1]}/output/ascii/{file_name}\",header=header)\n",
    "\n",
    "df_lavrion_375 = pd.concat([df_lavrion_375_1, df_lavrion_375_2], axis=0, ignore_index=True)\n",
    "df_lavrion_375.name = \"Lavrion 37.5GHz\"\n",
    "\n",
    "df_lavrion_75_1 = pd.read_csv(f\"data/{folders_name[2]}/output/ascii/{file_name}\",header=header)\n",
    "df_lavrion_75_2 = pd.read_csv(f\"data/{folders_name[3]}/output/ascii/{file_name}\",header=header)\n",
    "\n",
    "df_lavrion_75 = pd.concat([df_lavrion_75_1, df_lavrion_75_2], axis=0, ignore_index=True)\n",
    "df_lavrion_75.name = \"Lavrion 75GHz\"\n",
    "\n",
    "df_ljubljana_375_1 = pd.read_csv(f\"data/{folders_name[4]}/output/ascii/{file_name}\",header=header)\n",
    "df_ljubljana_375_2 = pd.read_csv(f\"data/{folders_name[5]}/output/ascii/{file_name}\",header=header)\n",
    "\n",
    "df_ljubljana_375 = pd.concat([df_ljubljana_375_1, df_ljubljana_375_2], axis=0, ignore_index=True)\n",
    "df_ljubljana_375.name = \"Ljubljana 37.5GHz\"\n",
    "\n",
    "df_ljubljana_75_1 = pd.read_csv(f\"data/{folders_name[6]}/output/ascii/{file_name}\",header=header)\n",
    "df_ljubljana_75_2 = pd.read_csv(f\"data/{folders_name[7]}/output/ascii/{file_name}\",header=header)\n",
    "\n",
    "df_ljubljana_75 = pd.concat([df_ljubljana_75_1, df_ljubljana_75_2], axis=0, ignore_index=True)\n",
    "df_ljubljana_75.name = \"Ljubljana 75GHz\"\n",
    "\n",
    "dfs = [df_lavrion_375, df_lavrion_75, df_ljubljana_375, df_ljubljana_75]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "for data_df in dfs:\n",
    "    unique_elev = np.unique(data_df[\"Elevation_angle_deg\"])\n",
    "    fig = go.Figure()\n",
    "    for elev_angle in unique_elev:\n",
    "        temp_df =  data_df[data_df[\"Elevation_angle_deg\"] == elev_angle]\n",
    "        fig.add_trace(go.Scatter(x=temp_df['Time_exceeded_%'], y=temp_df[att_col], name=f\"Elevation {elev_angle}\"))\n",
    "        fig.add_trace(go.Scatter(mode='markers',marker_symbol=\"x\",x=temp_df['Time_exceeded_%'], y=temp_df[att_col],name=f\"Elevation {elev_angle}\"))\n",
    "\n",
    "    fig.update_xaxes(type=\"log\")\n",
    "    fig.update_layout(title=f\"{data_df.name}, {file_name}\", xaxis_title=\"Time exceeded  [%]log\", yaxis_title=f\"Attenuation {selected_attenuation} [dB]\")\n",
    "    fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attenuation with respect of elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_exceeded=data_df['Time_exceeded_%'].array[0]\n",
    "print(\"Time exceeded: \", time_exceeded,\"%\")\n",
    "for data_df in dfs:\n",
    "    threshold_vs_elev = []\n",
    "\n",
    "    for elev in stat.index.array[:-1]:\n",
    "        threshold_vs_elev.append(data_df[data_df['Elevation_angle_deg']==elev][att_col][data_df['Time_exceeded_%']==time_exceeded].array[0]) # \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=stat.index.array[:-1],y=threshold_vs_elev))\n",
    "    fig.update_layout(title=f\"{data_df.name}, {selected_attenuation} attenuation\", xaxis_title=\"elevation [degrees]\", yaxis_title=f\" {selected_attenuation} Attenuation[dB]\")    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute average attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponderated_df = {}\n",
    "interpolation_number =100\n",
    "for data_df in dfs:\n",
    "    ponderated_attenuation = 0\n",
    "    new_percentage = np.geomspace(data_df[data_df['Elevation_angle_deg']==5]['Time_exceeded_%'].array[0],data_df[data_df['Elevation_angle_deg']==5]['Time_exceeded_%'].array[-1],interpolation_number)\n",
    "    for elev in stat.index.array[:-1]:\n",
    "        fcn = interpolate.interp1d(data_df[data_df['Elevation_angle_deg']==elev]['Time_exceeded_%'].array,data_df[data_df['Elevation_angle_deg']==elev][att_col].array)\n",
    "        ponderated_attenuation += fcn(new_percentage)*stat['PDF'][elev]/100\n",
    "        #ponderated_attenuation +=  data_df[data_df['Elevation_angle_deg']==elev][att_col].array*stat['PDF'][elev]/100 # /100 to transform % to decimal\n",
    "    ponderated_df[data_df.name] = {'attenuation':ponderated_attenuation,'time_exceeded':new_percentage}\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=new_percentage,y=ponderated_attenuation))\n",
    "    #fig.add_trace(go.Scatter(x=data_df['Time_exceeded_%'],y=ponderated_attenuation)) ## Without interpolation\n",
    "    fig.update_xaxes(type=\"log\")\n",
    "    fig.update_layout(title=f\"{data_df.name}, {selected_attenuation} attenuation\", xaxis_title=\"Time exceeded  [%]log\", yaxis_title=f\" {selected_attenuation} Attenuation[dB]\")    \n",
    "    fig.add_vline(x=1, line_width=3, line_dash=\"dash\", line_color=\"red\")\n",
    "    fig.add_vline(x=0.5, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x=0.1, line_width=3, line_dash=\"dash\", line_color=\"yellow\")\n",
    "    fig.add_vline(x=0.01, line_width=3, line_dash=\"dash\", line_color=\"orange\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmitter EIRP calculation\n",
    "\n",
    "EIRP = SNR - Gr + L + N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "def avg_distances(city_name):\n",
    "    ## Average distance calculation\n",
    "    pkl_name= f\"./coordinates_{city_name}.pkl\" \n",
    "    pkl_pdf_name= f\"./stat_{city_name}.pkl\" \n",
    "    coord_df = pd.DataFrame(pd.read_pickle(pkl_name))\n",
    "\n",
    "    ind  = np.logical_and( 0 <= coord_df['EL'] , coord_df['EL'] < 90) # For all elevation that are in the range 0, 90 degrees\n",
    "    distances = coord_df['DISTANCES'][ind]\n",
    "    print(\"Distances statistics\")\n",
    "    print(coord_df['DISTANCES'][np.logical_and( 0 <= coord_df['EL'] , coord_df['EL'] < 90)].describe())\n",
    "\n",
    "    return np.mean(distances) # Earth-satellite mean distance [meter]\n",
    "\n",
    "## To EDIT\n",
    "T = 500                                     # System temperature [Kelvin]\n",
    "Gr = 51                                   # Receive antenna gain [dB]\n",
    "city_name='lavrion'                       # City name used to compute the average distance betzeen BS and satellite\n",
    "selected_bs_freq = 'Lavrion 75GHz'        # ponderated_df_keys = ['Lavrion 37.5GHz', 'Lavrion 75GHz', 'Ljubljana 37.5GHz', 'Ljubljana 75GHz'] used to get ponderated attenuation\n",
    "fr = 75*10**9                               # frequency GHz\n",
    "\n",
    "\n",
    "## Constants\n",
    "k = 1.381e-23 # boltzman constant\n",
    "B = 50        # Receiver bandwidth [Hz]\n",
    "SNR = 10      # signal to noise ratio [dB]\n",
    "\n",
    "N = 10*np.log10(k * T * B)  # Noise level\n",
    "\n",
    "lamda = 3*10**8/fr # wavelength [meter]\n",
    "\n",
    "\n",
    "r=avg_distances(city_name)\n",
    "\n",
    "\n",
    "## Loss calculation\n",
    "L_0 = 20*np.log10(4*np.pi*r*1000/lamda) # free space loss [dB]\n",
    "L_atm = ponderated_df[selected_bs_freq]['attenuation'] # Atmospheric attenuation for every probability [dB]\n",
    "L_misc = 6                              # Micellaneous loss [dB]\n",
    "\n",
    "\n",
    "L = L_0+L_atm+L_misc                    # total path loss\n",
    "\n",
    "\n",
    "eirp = SNR + N + L - Gr\n",
    "\n",
    "time_exceeded = ponderated_df[selected_bs_freq]['time_exceeded']\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time_exceeded,y=eirp))\n",
    "fig.update_layout(title=f\"{selected_bs_freq}\", xaxis_title=\"Time exceeded  [%]log\", yaxis_title=f\"EIRP [dB]\")    \n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0a6418f5a2ddd18444d026a94ad36da0e3b74fe629d7d82274bf9e4a91dc94b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
